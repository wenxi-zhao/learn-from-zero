---
title: 5 Probability and Statistics
navigation:
index: 6
icon: i-ph-info-duotone
---

## 1. 概率是什么？
概率我们肯定知道是什么，就是来描述某件事情发生的可能性大小。比如我打赌今天饭堂有宫保鸡丁，那能否有宫保鸡丁这件事，就被称为概率事件。概率也跟赌博息息相关，比如在美国大选年中，大家都在猜测谁会是下一任总统，特朗普上任的概率有多少？而这些可能性都是能通过计算来预估的，这也是我们为什么学习概率与统计。

接下来，我们会参考[《动手学习深度学习》--李沐](https://zh.d2l.ai/chapter_preliminaries/probability.html) 这本书来为大家简单介绍什么是概率论。同时也会应用第3章提到的`Numpy`并使用代码和数学公式运算。

## 2. 基本概率论

概率论是一门用数学语言来描述随机事件的学科（大学课程）。它主要研究以下几个基本概念：

### 基本定义

- 随机事件: 生活中具有不确定性的事件

- 概率: 用 0-1 之间的数值来描述事件发生的可能性
    - 0 表示不可能发生
    - 1 表示一定会发生


让我们通过一个简单的抽奖游戏来理解概率论的基本概念。

- 基本概率的计算方法
- 如何用Python进行概率实验
- 如何通过可视化来理解概率分布
- 理论概率与实验概率的关系

首先，我们安装和导入必要的软件包。

::code-mirror-run{:editable="true" maxHeight="20rem" :showInCol="true"}
```python
  import pyodide_js
  await pyodide_js.loadPackage("micropip")

  import micropip
  await micropip.install("numpy")
  await micropip.install("matplotlib")
```
::


#### 抽奖游戏案例

假设有一个抽奖箱,里面有:
- 30个红球(一等奖)
- 50个蓝球(二等奖) 
- 120个白球(未中奖)

问题:抽一个球,抽到各种球的概率是多少?

##### 理论计算

根据概率论的基本定义:
````
某个事件的概率 = 该事件发生的可能数 ÷ 所有可能的结果总数
````

所以:
- 抽到红球概率 = 30/(30+50+120) = 0.15 (15%)
- 抽到蓝球概率 = 50/(30+50+120) = 0.25 (25%)
- 抽到白球概率 = 120/(30+50+120) = 0.60 (60%)

#### 用Python模拟验证

这里简单说明下模拟验证是一种重要的研究方法，也是一门专门将这个的大学课程。我们可以通过模拟数据来推断出这个事件的概率。比如说我们要发射火箭，不可能发��一千次来得出成功概率吧。这时候就要通过反复模拟数据来验证并不断提高我们成功概率。


接着，让我们用代码来模拟这个抽奖过程:

::code-mirror-run{:editable="true" maxHeight="20rem" :showInCol="true"}
```python
import numpy as np

# Set random seed for reproducibility
np.random.seed(42)

# Create prize pool (1=red, 2=blue, 3=white)
prize_pool = np.array([1]*30 + [2]*50 + [3]*120)

# Different numbers of trials
n_trials_list = [100, 1000, 10000]

print("Simulation Probability Results:")
print("-" * 40)
print("Trials\t\tRed\t\tBlue\t\tWhite")
print("Theory:\t\t0.150\t\t0.250\t\t0.600")
print("-" * 40)

# Perform simulations with different numbers of trials
for n_trials in n_trials_list:
    results = np.random.choice(prize_pool, size=n_trials)
    unique, counts = np.unique(results, return_counts=True)
    probabilities = counts / n_trials
    print(f"{n_trials}:\t\t{probabilities[0]:.3f}\t\t{probabilities[1]:.3f}\t\t{probabilities[2]:.3f}")
```
::

![Probability Distribution Simulation](/images/probability_simulation.png)

#### 理解要点

1. **样本空间**: 所有可能的结果构成样本空间,这里是200个球的集合

2. **事件**: 从样本空间中抽取的特定结果,比如抽到红球就是一个事件

3. **概率**: 
   - 理论概率是根据可能性计算得出
   - 实际概率可以通过大量实验来估计
   - 当实验次数越多,实验概率会越接近理论概率

4. **大数定律**: 
   - 通过增加实验次数(比如从1000次增加到10000次),实验结果会更接近理论值
   - 这就是为什么我们在代码中模拟了大量次数的抽奖




### 2.1概率论公理

在前面的抽奖游戏中，我们已经初步了解了概率的基本概念。现在让我们通过这个例子来深入理解概率论的基本公理。

其实概率主要是研究两件事情
1.样本空间
2.概率函数

#### 样本空间

样本空间（Sample Space）是所有可能结果的集合。在我们的抽奖游戏中：
- 样本空间 S = {红球, 蓝球, 白球}
- 每个球代表一个基本事件
- 总共有200个球，构成了完整的样本空间

#### 概率函数

概率函数（Probability Function）是将事件映射到实数的函数，它必须满足以下公理：

1. **非负性**：对任何事件A，概率必须大于等于0
   - P(红球) = 0.15 > 0
   - P(蓝球) = 0.25 > 0
   - P(白球) = 0.60 > 0

2. **规范性**：样本空间S中所有事件的概率和为1
   - P(红球) + P(蓝球) + P(白球) = 0.15 + 0.25 + 0.60 = 1

3. **可加性**：对于互不相容的事件，其并集的概率等于各个事件概率的和
   - 例如：P(抽到奖品) = P(红球) + P(蓝球) = 0.15 + 0.25 = 0.40


#### 条件概率

在抽奖游戏中，我们还可以引入条件概率的概念。例如：
- 如果已知抽到了奖品，那么是红球的概率是多少？
- P(红球|中奖) = P(红球) / P(中奖) = 0.15 / 0.40 = 0.375

这说明在已知中奖的情况下，有37.5%的概率是一等奖（红球）。

#### 独立性

两个事件A和B是独立的，意味着一个事件的发生不影响另一个事件的概率。在我们的抽奖游戏中：
- 如果放回抽取：每次抽奖都是独立的
- 如果不放回抽取：事件之间不独立，因为前一次的结果会影响后续概率

### 2.2 随机变量

随机变量是概率论中的一个核心概念，它是从样本空间到实数集的函数映射。简单来说，随机变量就是随机试验各种结果的数值表示。

#### 离散随机变量

离散随机变量是指其取值只能是有限个或可数无限个的随机变量。

让我们继续用抽奖游戏来理解：
- X = 抽到的奖品价值
  - 红球(一等奖) = 1000元
  - 蓝球(二等奖) = 500元
  - 白球(未中奖) = 0元

这里的X就是一个离散随机变量，因为它只能取这三个特定的值。

::code-mirror-run{:editable="true" maxHeight="20rem" :showInCol="true"}
```python
import numpy as np

# 定义奖品价值
prizes = {
    1: 1000,  # 红球价值1000元
    2: 500,   # 蓝球价值500元
    3: 0      # 白球价值0元
}

# 模拟1000次抽奖
np.random.seed(42)
draws = np.random.choice([1, 2, 3], size=1000, p=[0.15, 0.25, 0.60])

# 计算期望值（平均奖金）
expected_value = sum(prizes[ball] * count/1000 
                    for ball, count in zip(*np.unique(draws, return_counts=True)))

print("抽奖模拟结果:")
print(f"平均奖金: {expected_value:.2f}元")
print("\n各种情况出现的次数:")
for ball, count in zip(*np.unique(draws, return_counts=True)):
    print(f"价值{prizes[ball]}元的奖品: {count}次 ({count/10:.1f}%)")
```
::

#### 连续随机变量

连续随机变量是指其取值可以是某个区间内的任意实数的随机变量。

例如：某个工厂生产的灯泡寿命X（单位：小时）
- X可以是1000到2000之间的任何实数
- 不同寿命的概率用概率密度函数来描述

让我们模拟灯泡寿命的分布：

::code-mirror-run{:editable="true" maxHeight="20rem" :showInCol="true"}
```python
import numpy as np

# 生成1000个服从正态分布的灯泡寿命数据
# 均值1500小时，标准差100小时
np.random.seed(42)
lifetimes = np.random.normal(1500, 100, 1000)

# 计算基本统计量
mean_lifetime = np.mean(lifetimes)
std_lifetime = np.std(lifetimes)
min_lifetime = np.min(lifetimes)
max_lifetime = np.max(lifetimes)

print("灯泡寿命统计:")
print(f"平均寿命: {mean_lifetime:.2f}小时")
print(f"标准差: {std_lifetime:.2f}小时")
print(f"最短寿命: {min_lifetime:.2f}小时")
print(f"最长寿命: {max_lifetime:.2f}小时")

# 计算不同寿命区间的灯泡数量
intervals = [1200, 1400, 1600, 1800]
counts = np.histogram(lifetimes, bins=intervals)[0]
print("\n寿命分布:")
for i in range(len(counts)):
    start = intervals[i]
    end = intervals[i+1]
    count = counts[i]
    print(f"{start}-{end}小时: {count}个 ({count/10:.1f}%)")
```
::

#### 随机变量的主要特征

1. **期望值(E(X))**
   - 离散：每个可能值与其概率的乘积之和
   - 连续：概率密度函数与值的积分

2. **方差(Var(X))**
   - 描述随机变量的离散程度
   - 方差越大，数据分布越分散

3. **分布函数**
   - 离散：概率质量函数(PMF)
   - 连续：概率密度函数(PDF)

#### 实际应用

随机变量在实际生活中有广泛应用：

1. **质量控制**
   - 产品尺寸（连续）
   - 产品缺陷数（离散）

2. **金融分析**
   - 股票价格（连续）
   - 每日交易次数（离散）

3. **医学研究**
   - 病人康复时间（连续）
   - 每日新增病例数（离散）

理解随机变量的类型和特征，对于正确建模和分析实际问题至关重要。在机器学习中，我们经常需要处理这两类随机变量，并根据它们的特性选择合适的模型和算法。


## 3. 处理多个随机变量

在现实世界中，我们经常需要同时处理多个随机变量。让我们通过一个医疗诊断的例子来理解：

假设我们关注两个随机变量：
- D：患者是否患有某种疾病（阳性或阴性）
- T：诊断测试的结果（阳性或阴性）

这个例子涉及了多种概率：

### 3.1 基本概率类型

1. **联合概率 P(D,T)**
   - 两个事件同时发生的概率
   - 例：P(患病且测试阳性)

2. **边缘概率 P(D) 或 P(T)**
   - 单个事件发生的概率
   - 例：P(患病) 或 P(测试阳性)

3. **条件概率 P(D|T)**
   - 在已知一个事件发生的情况下，另一个事件发生的概率
   - 例：P(患病|测试阳性) = 测试呈阳性时实际患病的概率

### 3.2 贝叶斯定理：概率论的基石

贝叶斯定理是概率论中最重要的定理之一，它为我们提供了更新信念的数学框架。在机器学习和人工智能领域，它是许多算法的理论基础。

#### 数学公式

$$P(D|T) = \frac{P(T|D)P(D)}{P(T)}$$

其中：
- P(D|T) 是后验概率：在观察到证据T后，对D的新认识
- P(T|D) 是似然性：在D成立的条件下观察到T的概率
- P(D) 是先验概率：在观察T之前对D的认识
- P(T) 是标准化常数：所有可能情况的概率和

#### 医疗诊断案例的代码实现

::code-mirror-run{:editable="true" maxHeight="20rem" :showInCol="true"}
```python
import numpy as np

# 已知概率
P_disease = 0.01  # 疾病发病率（先验概率）
P_positive_given_disease = 0.95  # 患病者测试阳性的概率（敏感性）
P_negative_given_healthy = 0.90  # 健康者测试阴性的概率（特异性）

# 计算P(T)：测试呈阳性的总概率
P_positive = (P_positive_given_disease * P_disease + 
             (1 - P_negative_given_healthy) * (1 - P_disease))

# 使用贝叶斯定理计算后验概率
P_disease_given_positive = (P_positive_given_disease * P_disease) / P_positive

print("医疗诊断概率分析:")
print(f"疾病发病率: {P_disease:.1%}")
print(f"测试准确率（敏感性）: {P_positive_given_disease:.1%}")
print(f"测试特异性: {P_negative_given_healthy:.1%}")
print(f"\n如果测试呈阳性，实际患病的概率: {P_disease_given_positive:.1%}")
```
::

#### 贝叶斯定理的重要性

1. **不确定性的量化**
   - 帮助我们在获得新信息后更新概率估计
   - 提供了处理不确定性的数学框架

2. **机器学习应用**
   - 朴素贝叶斯分类器
   - 贝叶斯神经网络
   - 概率图模型

3. **决策支持**
   - 医疗诊断
   - 风险评估
   - 科学推理

4. **现代AI基础**
   - 概率推理
   - 不确定性建模
   - 自适应学习系统

贝叶斯定理不仅是一个数学公式，更是一种思维方式。它教会我们如何在获得新证据时理性地更新我们的信念，这在当今的数据时代显得尤为重要。无论是在医疗诊断、垃圾邮件过滤，还是人工智能系统中，贝叶斯方法都发挥着关键作用。



## GPU与深度学习的革命性突破

### GPU的崛起与影响

图形处理器(GPU)最初是为了处理图形和游戏而设计的。然而，研究人员发现GPU的并行计算架构非常适合处理机器学习中的大规模数学运算。自2000年以来，GPU的性能每十年提升约1000倍，这种指数级的增长为深度学习的发展提供了强大的硬件基础。

NVIDIA公司通过推出CUDA(统一计算设备架构)平台，让GPU不再局限于图形处理，而是成为了通用的并行计算处理器。这一转变彻底改变了深度学习的发展轨迹。传统的CPU处理器擅长串行运算，而GPU则可以同时处理成千上万的并行任务，这正好符合深度学习中大规模矩阵运算的需求。


### GPU对机器学习的革命性影响

1. **训练速度的质的飞跃**：原本需要数周才能完成的模型训练，现在可能只需要几个小时。这大大加快了算法开发和模型优化的速度。

2. **更大规模的模型成为可能**：从最早的几层神经网络，到现在的数千亿参数的大模型（如GPT系列），这种发展离不开GPU的算力支持。

3. **降低了入门门槛**：研究人员不需要昂贵的超级计算机，用一台配备GPU的个人电脑就能进行深度学习研究。

### 在概率统计中的应用

在概率统计领域，GPU的并行计算能力同样带来了革命性的变化。例如在蒙特卡洛模拟中，我们可以同时进行数百万次随机试验，这在传统CPU上是难以实现的。这种计算能力的提升让我们能够：
- 处理更大规模的数据集
- 进行更精确的概率估计
- 实现更复杂的统计模型

### 实际案例：天气预报模型

让我们以天气预报模型为例来说明GPU的重要性：

传统的天气预报模型需要考虑数百万个数据点（温度、气压、风速等），并且要进行大量的概率计算来预测未来天气。在CPU时代，制作一份准确的48小时天气预报可能需要24小时的计算时间，这意味着当预报结果出来时，已经错过了最佳的预报窗口。

而使用GPU加速后：
1. 计算时间可能缩短到1-2小时
2. 可以同时计算多个可能的天气情景
3. 能够处理更高分辨率的气象数据
4. 预报的准确度和时效性都得到显著提升

这个例子很好地展示了GPU如何通过其强大的并行计算能力，改变了传统的计算密集型任务的处理方式。同样的革命性变化也发生在金融分析、基因测序、药物研发等众多领域。

### 未来展望

随着AI技术的不断发展，对算力的需求也在持续增长。新一代的GPU架构（如NVIDIA的Hopper架构）和专用AI芯片的出现，预示着我们正在进入一个计算能力爆炸式增长的新时代。这将为机器学习和深度学习带来更多可能性，推动人工智能技术向更广更深的方向发展。

[参考：深度学习计算 - 使用GPU](https://zh.d2l.ai/chapter_deep-learning-computation/use-gpu.html)